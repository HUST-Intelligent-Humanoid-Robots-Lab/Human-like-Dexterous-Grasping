# Human-like-Dexterous-Grasping
A collection of papers, codes and resources related to human-like dexterous multi-fingered grasping.

## Papers

### Survey
[Dexterous Manipulation for Multi-Fingered Robotic Hands With Reinforcement Learning: A Review](https://www.semanticscholar.org/paper/Dexterous-Manipulation-for-Multi-Fingered-Robotic-A-Yu-Wang/1ee71262c4525bca44c6da5b8e1321a67a484953) Frontiers in Neurorobotics 2022

### Deep Learning

[DexTransfer: Real World Multi-fingered Dexterous Grasping with Minimal Human Demonstrations](https://arxiv.org/abs/2209.14284) arXiv 2022

[CaTGrasp: Learning Category-Level Task-Relevant Grasping in Clutter from Simulation](https://arxiv.org/pdf/2109.09163.pdf) arXiv 2022 | [website](https://sites.google.com/view/catgrasp) | [code](https://github.com/wenbowen123/catgrasp)

[Toward Human-Like Grasp : Dexterous Grasping via Semantic Representation of Object-Hand](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9156512) ICCV 2021

[Multi-FinGAN: Generative Coarse-To-Fine Sampling of Multi-Finger Grasps](https://arxiv.org/abs/2012.09696) ICRA 2021 | [code](https://github.com/aalto-intelligent-robotics/Multi-FinGAN)

[DDGC: Generative Deep Dexterous Grasping in Clutter](https://arxiv.org/abs/2103.04783) IROS 2021 | [code](https://github.com/aalto-intelligent-robotics/DDGC)

[Synergies Between Affordance and Geometry: 6-DoF Grasp Detection via Implicit Representations](https://arxiv.org/abs/2104.01542) arXiv 2021 | [website](https://sites.google.com/view/rpl-giga2021) | [code](https://github.com/UT-Austin-RPL/GIGA)

[Learning Task-Oriented Grasping from Human Activity Datasets](https://arxiv.org/pdf/1910.11669.pdf) RAL 2020 | [video](https://www.youtube.com/watch?v=aIRzoPFmLDw)

[Learning Grasp Affordance Reasoning through Semantic Relations](https://arxiv.org/pdf/1906.09836.pdf) RAL 2019 | [video](https://www.youtube.com/watch?v=aaA3NA-S5KY) | [website](https://paolaardon.github.io/grasp_affordance_reasoning/) | [code](https://github.com/PaolaArdon/grasp_affordance_reasoning_demo)

[Learning from humans how to grasp: A data-driven architecture for autonomous grasping with anthropomorphic soft hands](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8629968) RAL 2019

[Affordance Detection for Task-Specific Grasping Using Deep Learning](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8239542) Humanoids 2017

### Deep Renforcement Learning
[Learning Dexterous Grasping with Object-Centric Visual Affordances](https://arxiv.org/pdf/2009.01439.pdf) ICRA 2021 | [website](https://vision.cs.utexas.edu/projects/graff-dexterous-affordance-grasp/)

[DexVIP: Learning Dexterous Grasping with Human Hand Pose Priors from Video](https://arxiv.org/abs/2202.00164) CoRL 2021 | [webisite](https://vision.cs.utexas.edu/projects/dexvip-dexterous-grasp-pose-prior/)

[Natural object manipulation using anthropomorphic robotic hand through deep reinforcement learning and deep grasping probability network](https://link.springer.com/content/pdf/10.1007/s10489-020-01870-6.pdf) Applied Intelligence 2021

[Learning Task-Oriented Dexterous Grasping from Human Knowledge](http://sro.sussex.ac.uk/id/eprint/97502/1/ICRA21__home_papercept_ras.papercept.net_www_conferences_conferences_ICRA21_submissions_2332_MS.pdf) ICRA 2021


### Human Grasp Inspired
[D-Grasp: Physically Plausible Dynamic Grasp Synthesis for Hand-Object Interactions](https://arxiv.org/pdf/2112.03028.pdf) CVPR 2022 | [website](https://eth-ait.github.io/d-grasp/) | [code](https://github.com/christsa/dgrasp)

[DexMV: Imitation Learning for Dexterous Manipulation from Human Videos](https://arxiv.org/pdf/2108.05877.pdf) ECCV 2022 | [website](https://yzqin.github.io/dexmv/) | [code](https://github.com/yzqin/dexmv-sim)

[Learning Continuous Grasping Function with a Dexterous Hand from Human Demonstrations](https://arxiv.org/pdf/2207.05053.pdf) arXiv 2022 | [website](https://jianglongye.com/cgf/) | [code:coming soon]

[Learning Generalizable Dexterous Manipulation from Human Grasp Affordance](https://arxiv.org/abs/2204.02320) arXiv 2022 | [website](https://kristery.github.io/ILAD/?utm_source=catalyzex.com) | [code:coming soon]

[Towards Unconstrained Joint Hand-Object Reconstruction From RGB Videos](https://arxiv.org/pdf/2108.07044v2.pdf) arXiv 2022 | [website](https://hassony2.github.io/homan.html) | [code](https://github.com/hassony2/homan)

[Hand-Object Contact Consistency Reasoning for Human Grasps Generation](https://arxiv.org/pdf/2104.03304.pdf) arXiv 2021 | [website](https://hwjiang1510.github.io/GraspTTA/) | [code](https://github.com/hwjiang1510/GraspTTA)

[CPF: Learning a Contact Potential Field to Model the Hand-Object Interaction](https://paperswithcode.com/paper/cpf-learning-a-contact-potential-field-to) ICCV 2021 | [code](https://github.com/lixiny/CPF)

[Grasping Field: Learning Implicit Representations for Human Grasps](https://arxiv.org/pdf/2008.04451v3.pdf) arXiv 2020 | [code](https://github.com/korrawe/grasping_field)

[Ganhand: Predicting human grasp affordances in multi-object scenes](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhu_Toward_Human-Like_Grasp_Dexterous_Grasping_via_Semantic_Representation_of_Object-Hand_ICCV_2021_paper.pdf) CVPR 2020 | [website](http://www.iri.upc.edu/people/ecorona/ganhand/) | [code](https://github.com/enriccorona/GanHand)

[Learning joint reconstruction of hands and manipulated objects](https://arxiv.org/pdf/1904.05767v1.pdf) arXiv 2019 | [code](https://github.com/hassony2/manopth)


### Other Method
[Generalization in Dexterous Manipulation via Geometry-Aware Multi-Task Learning](https://arxiv.org/pdf/2111.03062.pdf) ArXiv 2022 | [website](https://wenlong.page/geometry-dex/) | [code](https://github.com/huangwl18/geometry-dex/tree/main)

[Object affordance as a guide for grasp-type recognition](https://arxiv.org/pdf/2103.00268.pdf) ArXiv 2021 | [code](https://github.com/microsoft/arr-grasp-type-recognition)

[Grasp It like a Pro: Grasp of Unknown Objects with Robotic Hands based on Skilled Human Expertise](https://manipulation-iros-workshop.github.io/static/assets/img/papers/main.pdf) RAL 2020

[ContactGrasp: Functional Multi-finger Grasp Synthesis from Contact](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8967960) IROS 2019 | [video](https://www.youtube.com/watch?v=oico10ih54c) | [website](https://contactdb.cc.gatech.edu/contactgrasp.html) | [code](https://github.com/contactgrasp/dart) 



## Datasets
[A Large-scale Knowledge Repository for Understanding Hand-Object Interaction](https://arxiv.org/pdf/2203.15709v1.pdf) CVPR 2022 | [website](https://oakink.net/) | [code](https://github.com/lixiny/oakink)

[DexYCB: A Benchmark for Capturing Hand Grasping of Objects](https://arxiv.org/pdf/2104.04631v1.pdf) CVPR 2021 | [website](https://dex-ycb.github.io/) | [code](https://github.com/NVlabs/dex-ycb-toolkit)

[ContactPose: A Dataset of Grasps with Object Contact and Hand Pose](https://arxiv.org/abs/2007.09545) ECCV 2020 | [website](https://contactpose.cc.gatech.edu/) | [code](https://github.com/facebookresearch/ContactPose)

[GRAB: A Dataset of Whole-Body Human Grasping of Objects](https://arxiv.org/pdf/2008.11200v1.pdf) ECCV 2020 | [website](https://grab.is.tue.mpg.de/) | [code](https://github.com/otaheri/GRAB)

[YCB-Affordance Dataset](https://github.com/enriccorona/YCB_Affordance)

## Researchers & Groups
