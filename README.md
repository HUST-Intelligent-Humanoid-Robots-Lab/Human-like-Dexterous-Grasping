# awesome-human-like-multi-fingered-grasping[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
A collection of papers, codes and resources of human-like functional multi-fingered grasping.

## Papers

### Survey/Datasets

[What Matters in Learning from Offline Human Demonstrations for Robot Manipulation](https://arxiv.org/pdf/2108.03298.pdf) arxiv2021 | [website](https://robomimic.github.io/) |[code](https://github.com/ARISE-Initiative/robomimic)

### Deep Learning

[Toward Human-Like Grasp : Dexterous Grasping via Semantic Representation of Object-Hand](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9156512) ICCV 2021

[Ganhand: Predicting human grasp affordances in multi-object scenes](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhu_Toward_Human-Like_Grasp_Dexterous_Grasping_via_Semantic_Representation_of_Object-Hand_ICCV_2021_paper.pdf) CVPR 2020 | [video](https://www.youtube.com/watch?v=1rN66OC6fyc) | [code](https://github.com/enriccorona/GanHand)


### Deep Renforcement Learning

[Learning Dexterous Grasping with Object-Centric Visual Affordances](https://arxiv.org/pdf/2009.01439.pdf) ICRA 2021 | [website](https://vision.cs.utexas.edu/projects/graff-dexterous-affordance-grasp/)

[Natural object manipulation using anthropomorphic robotic hand through deep reinforcement learning and deep grasping probability network](https://link.springer.com/content/pdf/10.1007/s10489-020-01870-6.pdf) Applied Intelligence 2021


## Talks

[Visual Imitation Learning: Generalization, Perceptual Grounding, and Abstraction](https://www.youtube.com/watch?v=1TJHuO5TAfo) RSS Workshop 2020 

